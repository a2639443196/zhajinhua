import json
import re
import time
import asyncio
import ast
from typing import List, Dict, Callable, Awaitable, Optional, Tuple
from llm_client import LLMClient
import pathlib
import traceback  # (æ–°) å¯¼å…¥ traceback

BASE_DIR = pathlib.Path(__file__).parent.resolve()
DECIDE_ACTION_PROMPT_PATH = BASE_DIR / "prompt/decide_action_prompt.txt"
REFLECT_PROMPT_PATH = BASE_DIR / "prompt/reflect_prompt_template.txt"
CREATE_PERSONA_PROMPT_PATH = BASE_DIR / "prompt/create_persona_prompt.txt"
DEFEND_PROMPT_PATH = BASE_DIR / "prompt/defend_prompt.txt"
VOTE_PROMPT_PATH = BASE_DIR / "prompt/vote_prompt.txt"


class Player:
    def __init__(self, name: str, model_name: str):
        self.name = name
        self.model_name = model_name
        self.llm_client = LLMClient()
        self.alive = True
        self.experience: float = 0.0  # (æ–°) è®°å½•ç‰Œå±€ç»éªŒ
        self.persona_tags: set[str] = set()
        self.persona_text: str = ""
        self.play_history: List[str] = []
        self.current_pressure: float = 0.0
        self.cheat_attempts: int = 0
        self.cheat_success: int = 0
        self.mindgame_moves: int = 0

        # [æ–°] é“å…·ç³»ç»Ÿï¼šèƒŒåŒ…å†…å­˜æ”¾ç©å®¶å·²ç»è·å¾—çš„é“å…·ID
        self.inventory: List[str] = []

        # [æ–°] è´·æ¬¾ç³»ç»Ÿï¼šè®°å½•æœªæ¸…è´·æ¬¾çš„åˆ°æœŸæ‰‹æ•°ä¸é‡‘é¢
        self.loan_data: Dict[str, int] = {}

    # --- (æ–°) ç»éªŒç³»ç»Ÿè¾…åŠ©å¸¸é‡ ---
    _EXPERIENCE_KEYWORDS: Dict[str, float] = {
        "è€æ‰‹": 18.0,
        "èµ„æ·±": 16.0,
        "èŒä¸š": 15.0,
        "å† å†›": 14.0,
        "é«˜æ‰‹": 12.0,
        "å®—å¸ˆ": 20.0,
        "å†·é™": 6.0,
        "æ²‰ç€": 6.0,
        "è€ç»ƒ": 10.0,
        "ç»éªŒ": 8.0,
        "ä»å®¹": 5.0,
        "ç®—è®¡": 7.0,
        "å¿ƒç†æˆ˜": 7.5,
    }
    _AGGRESSIVE_KEYWORDS = {"æ¿€è¿›", "è¿›æ”»", "æ”»å‡»", "å†’é™©", "è±ªèµŒ"}
    _CAUTIOUS_KEYWORDS = {"ç¨³å¥", "è°¨æ…", "ä¿å®ˆ", "å†·é™", "ç†æ€§"}
    _DECEPTIVE_KEYWORDS = {"ä¼ªè£…", "éšè—", "æ©é¥°", "è¿·æƒ‘", "è¯ˆå”¬"}

    def register_persona(self, persona_text: str) -> None:
        """(æ–°) æ ¹æ®äººè®¾åˆå§‹åŒ–ç»éªŒæ ‡ç­¾ã€‚"""
        self.persona_text = persona_text or ""
        base_score = 12.0  # é»˜è®¤ç»™ä¸€ä¸ªåŸºç¡€ç»éªŒï¼Œé¿å…çº¯ 0
        lowered = self.persona_text.lower()
        for keyword, value in self._EXPERIENCE_KEYWORDS.items():
            if keyword in persona_text:
                base_score += value
        # æ£€æŸ¥è‹±æ–‡å…³é”®å­— (ä»¥é˜² prompt ä¸­æœ‰è‹±æ–‡æè¿°)
        for keyword, value in self._EXPERIENCE_KEYWORDS.items():
            if keyword.lower() in lowered:
                base_score += value * 0.6

        self.persona_tags.clear()
        if any(k in persona_text for k in self._AGGRESSIVE_KEYWORDS):
            self.persona_tags.add("aggressive")
        if any(k in persona_text for k in self._CAUTIOUS_KEYWORDS):
            self.persona_tags.add("cautious")
        if any(k in persona_text for k in self._DECEPTIVE_KEYWORDS):
            self.persona_tags.add("deceptive")

        self.experience = max(self.experience, base_score)

    def update_pressure_snapshot(self, chips: int, call_cost: int) -> None:
        """(æ–°) æ ¹æ®ç­¹ç ä¸æˆæœ¬ä¼°ç®—å‹åŠ›å€¼ (0~1)ã€‚"""
        if chips <= 0:
            pressure = 1.0
        else:
            ratio = call_cost / max(chips, 1)
            pressure = min(1.0, ratio * 0.85)

        low_stack_factor = 0.0
        if chips < 300:
            deficit_ratio = (300 - max(chips, 0)) / 300.0
            low_stack_factor = 0.35 + deficit_ratio * 0.45
        elif chips < call_cost * 2 and call_cost > 0:
            low_stack_factor = max(low_stack_factor, 0.15)

        if call_cost <= 0 and chips > 0:
            pressure = max(pressure, 0.12)

        pressure = min(1.0, pressure + low_stack_factor)

        mitigation = min(0.4, self.experience / 220.0)
        pressure *= (1.0 - mitigation)

        pressure += min(0.25, self.current_pressure * 0.3)

        self.current_pressure = max(0.0, min(1.0, pressure))

    def get_pressure_descriptor(self) -> str:
        """(æ–°) ç”¨ä¸­æ–‡æè¿°å½“å‰å‹åŠ›ã€‚"""
        if self.current_pressure >= 0.8:
            return "æ¿’ä¸´å´©æºƒ"
        if self.current_pressure >= 0.6:
            return "å‹åŠ›å±±å¤§"
        if self.current_pressure >= 0.4:
            return "ç´§å¼ "
        if self.current_pressure >= 0.2:
            return "å°šç®—ä»å®¹"
        return "æ‚ ç„¶è‡ªå¾—"

    def get_experience_level(self) -> str:
        """(æ–°) æ ¹æ®ç»éªŒå€¼ç»™å‡ºç­‰çº§ã€‚"""
        if self.cheat_success >= 4 and self.cheat_success >= max(1, self.cheat_attempts // 2):
            return "åƒç‹"
        if self.mindgame_moves >= 6 and self.experience >= 45:
            return "å¿ƒç†å­¦å¤§å¸ˆ"
        if self.experience >= 140:
            return "å®—å¸ˆ"
        if self.experience >= 90:
            return "å¤§å¸ˆ"
        if self.experience >= 60:
            return "é«˜æ‰‹"
        if self.experience >= 30:
            return "ç†Ÿç»ƒ"
        return "æ–°æ‰‹"

    def get_experience_summary(self) -> str:
        return f"{self.get_experience_level()} (ç»éªŒå€¼: {self.experience:.1f})"

    def get_mood_leak_probability(self) -> float:
        """(æ–°) ä¾æ®ç»éªŒä¸å‹åŠ›å†³å®šæƒ…ç»ªæ³„éœ²æ¦‚ç‡ã€‚"""
        base = 0.33 + (self.current_pressure - 0.5) * 0.22
        # (è°ƒæ•´) è½»å¾®æå‡æ•´ä½“æ³„éœ²æ¦‚ç‡ï¼Œä»¥åæ˜ æ›´é«˜çš„ç´§å¼ ä¸ä¾¦æµ‹ç¯å¢ƒ
        base += 0.05
        if self.experience >= 90:
            base *= 0.45
        elif self.experience >= 60:
            base *= 0.6
        elif self.experience <= 15:
            base *= 1.25
        return max(0.05, min(0.75, base))

    def update_experience_after_action(
            self,
            action_json: dict,
            cheat_context: Optional[dict] = None,
            call_cost: int = 0,
            current_pot: int = 0
    ) -> None:
        """(æ–° V2) æ ¹æ®åŠ¨ä½œã€é£é™©æ¯”ä¾‹å’Œå¿ƒç†æˆ˜æå‡ç»éªŒã€‚"""
        if not isinstance(action_json, dict):
            return

        action_name = str(action_json.get("action", "")).upper()
        if not action_name:
            return

        base_gain = 0.2  # åŸºç¡€å‚ä¸ç»éªŒ

        # ç»´åº¦1ï¼šåŠ¨ä½œé£é™©
        if action_name == "RAISE":
            # åŠ æ³¨ï¼šæ”¶ç›Šä¸åŠ æ³¨é¢ç›¸å¯¹äºåº•æ± çš„æ¯”ä¾‹æŒ‚é’©
            try:
                raise_amount = int(action_json.get("amount", 0))
            except (ValueError, TypeError):
                raise_amount = 0

            # (è·Ÿæ³¨æˆæœ¬ + (åŠ æ³¨å¢é‡ * å€ç‡)) - è¿™å¤ªå¤æ‚ï¼Œæˆ‘ä»¬åªçœ‹å¢é‡
            # æˆ‘ä»¬ç”¨ call_cost (å®ƒä»£è¡¨äº†å½“å‰ä¸‹æ³¨æ°´å¹³) ä½œä¸ºåŸºå‡†
            risk_ratio = min((raise_amount + call_cost) / max(current_pot, 1), 2.0)
            base_gain += 1.0 + (risk_ratio * 1.5)  # åŸºç¡€ 1.0 + é£é™©æ¯”ä¾‹åŠ æˆ

        elif action_name == "COMPARE":
            # æ¯”ç‰Œï¼šä¸­ç­‰é£é™©
            base_gain += 1.2

        elif action_name == "CALL":
            # è·Ÿæ³¨ï¼šæ”¶ç›Šä¸è·Ÿæ³¨é¢ç›¸å¯¹äºåº•æ± çš„æ¯”ä¾‹æŒ‚é’©
            risk_ratio = min(call_cost / max(current_pot, 1), 1.0)
            base_gain += 0.5 + (risk_ratio * 1.0)  # åŸºç¡€ 0.5 + é£é™©æ¯”ä¾‹åŠ æˆ

        elif action_name == "FOLD":
            # å¼ƒç‰Œï¼šä½æ”¶ç›Š
            base_gain += 0.3

        # ç»´åº¦2ï¼šäººè®¾åŠ æˆ (è´¯å½»äººè®¾)
        if "aggressive" in self.persona_tags and action_name in {"RAISE", "COMPARE", "ALL_IN_SHOWDOWN"}:
            base_gain += 0.5
        if "cautious" in self.persona_tags and action_name in {"FOLD", "CALL"}:
            base_gain += 0.4
        if "deceptive" in self.persona_tags and action_json.get("speech"):
            base_gain += 0.6  # è´¯å½»æ¬ºè¯ˆäººè®¾å¹¶å‘è¨€
            self.mindgame_moves += 1

        # ç»´åº¦3ï¼šä½œå¼Š (é«˜é£é™©/å›æŠ¥ï¼Œè¿™ç”±å¦ä¸€ä¸ªå‡½æ•°å¤„ç†)
        # cheat_context ä»…ç”¨äºæ ‡è®°ï¼Œå®é™…çš„ä½œå¼Šç»éªŒç”± update_experience_from_cheat å¤„ç†

        # ç»´åº¦4ï¼šç¤¾äº¤ (ç§˜å¯†æ¶ˆæ¯)
        secret_payload = action_json.get("secret_message")
        if isinstance(secret_payload, dict) and secret_payload.get("message"):
            base_gain += 1.0  # ç¤¾äº¤/å¯†è°‹ é¢å¤–åŠ æˆ
            self.mindgame_moves += 2

        self.experience = max(0.0, self.experience + base_gain)

    def update_experience_from_cheat(self, success: bool, cheat_type: str, context: Optional[dict] = None) -> None:
        """(æ–° V3) ä½œå¼Šç»“æœåé¦ˆç»éªŒï¼ŒåŒ…å«æ¶ˆè€—å’Œæ¬¡æ•°å¥–åŠ±ã€‚"""
        self.cheat_attempts += 1  # æ— è®ºæˆè´¥ï¼Œæ€»æ¬¡æ•°+1

        if success:
            self.cheat_success += 1

            # 1. [æ‚¨çš„è¦æ±‚ 3] æˆåŠŸä½œå¼Šçš„å›ºå®šæ¶ˆè€—
            # æ— è®ºå¦‚ä½•ï¼ŒæˆåŠŸä½œå¼Šéƒ½ä¼šæ¶ˆè€— 8.0 ç»éªŒå€¼
            CHEAT_SUCCESS_COST = 8.0

            # 2. [æ‚¨çš„è¦æ±‚ 2] æˆåŠŸä½œå¼Šçš„æ”¶ç›Š (åŸºç¡€ + ç±»å‹)
            base_gain = 5.0  # åŸºç¡€æˆåŠŸæ”¶ç›Š

            # (ä¿ç•™ V2 é€»è¾‘ï¼šä¸åŒç±»å‹æ”¶ç›Šä¸åŒ)
            if cheat_type.upper() == "SWAP_RANK":
                base_gain += 2.0  # æ¢ç‚¹æ•°æ”¶ç›Šæ›´é«˜
            elif cheat_type.upper() == "SWAP_SUIT":
                base_gain += 1.5

            # [æ‚¨çš„è¦æ±‚ 2] æ¬¡æ•°è¶Šå¤šï¼ŒæˆåŠŸæ”¶ç›Šè¶Šé«˜ (å¥–åŠ±"åƒç‹")
            # (self.cheat_success æ˜¯æˆåŠŸæ¬¡æ•°)
            # æ¯æ¬¡æˆåŠŸé¢å¤– +0.75 ç»éªŒï¼Œå°é¡¶ 10.0
            frequency_bonus = min(self.cheat_success * 0.75, 10.0)

            # æ€» delta = (æ”¶ç›Š + æ¬¡æ•°å¥–åŠ±) - æ¶ˆè€—
            delta = (base_gain + frequency_bonus) - CHEAT_SUCCESS_COST

        else:
            # 3. å¤±è´¥çš„æƒ©ç½š (é€»è¾‘ä¸å˜)
            delta = -6.0  # åŸºç¡€å¤±è´¥æƒ©ç½š
            if self.experience < 40:
                delta -= 2.0  # æ–°æ‰‹å¤±è´¥æ‰“å‡»æ›´å¤§
            if context and context.get("detected"):
                delta -= 2.5  # è¢«å½“åœºæŠ“ä½çš„é¢å¤–æƒ©ç½š

        self.experience = max(0.0, self.experience + delta)

    def update_experience_from_win(self, pot_at_showdown: int):
        """
        (æ–° V2) è·èƒœè€…ä¸“å±å¥–åŠ±ã€‚
        å¥–åŠ± = åŸºç¡€ 5.0 + 10% çš„æœ€ç»ˆåº•æ±  (ä¸Šé™ 20)
        """
        if pot_at_showdown <= 0:
            return

        # ç®—æ³•ï¼šåŸºç¡€åˆ† 5.0
        base_gain = 5.0

        # æ¯”ä¾‹ç®—æ³•ï¼šå¥–åŠ± 10% çš„åº•æ± å¤§å°ï¼Œè®¾ç½®ä¸€ä¸ªåˆç†çš„ä¸Šé™
        pot_bonus = min(pot_at_showdown * 0.1, 20.0)

        total_gain = base_gain + pot_bonus
        self.experience = max(0.0, self.experience + total_gain)

    def update_experience_from_reflection(self, reflection_text: str, private_notes: dict) -> None:
        """(æ–°) å¤ç›˜ä¹Ÿèƒ½æå‡ç»éªŒã€‚"""
        gain = 0.5
        if reflection_text:
            length_factor = min(len(reflection_text) / 120.0, 2.0)
            gain += length_factor
        if private_notes:
            gain += min(len(private_notes) * 0.6, 3.0)
        self.experience = max(0.0, self.experience + gain)

    def _extract_json_candidates(self, text: str) -> List[str]:
        """ä»ç»™å®šæ–‡æœ¬ä¸­æå–æ‰€æœ‰å¯èƒ½çš„ JSON ç‰‡æ®µã€‚"""
        candidates: List[str] = []
        stack: List[str] = []
        start_idx: Optional[int] = None

        for idx, ch in enumerate(text):
            if ch == '{':
                if not stack:
                    start_idx = idx
                stack.append(ch)
            elif ch == '}':
                if stack:
                    stack.pop()
                    if not stack and start_idx is not None:
                        candidates.append(text[start_idx: idx + 1])
                        start_idx = None

        return candidates

    def _safe_parse_json(self, candidate: str) -> Optional[Dict]:
        """å°½å¯èƒ½åœ°å°†å­—ç¬¦ä¸²è§£æä¸º JSON å¯¹è±¡ã€‚"""
        candidate = candidate.strip()
        if not candidate:
            return None

        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass

        last_brace = candidate.rfind('}')
        if last_brace != -1 and last_brace < len(candidate) - 1:
            trimmed = candidate[:last_brace + 1]
            try:
                return json.loads(trimmed)
            except json.JSONDecodeError:
                candidate = trimmed

        python_like = re.sub(r'\bnull\b', 'None', candidate)
        python_like = re.sub(r'\btrue\b', 'True', python_like)
        python_like = re.sub(r'\bfalse\b', 'False', python_like)

        try:
            data = ast.literal_eval(python_like)
        except Exception:
            return None

        if isinstance(data, dict):
            return data
        return None

    def _parse_first_valid_json(self, text: str) -> Optional[Dict]:
        # [å¥å£®æ€§ä¿®å¤]ï¼šæ”¹ä¸ºè¿”å› *æœ€å* ä¸€ä¸ªæœ‰æ•ˆçš„ JSONï¼Œä»¥å…è®¸ LLM è¿›è¡Œè‡ªæˆ‘ä¿®æ­£ã€‚
        last_valid_json: Optional[Dict] = None
        for candidate in self._extract_json_candidates(text):
            parsed = self._safe_parse_json(candidate)
            if isinstance(parsed, dict):
                last_valid_json = parsed  # æŒç»­è¦†ç›–ï¼Œç›´åˆ°æœ€åä¸€ä¸ª

        return last_valid_json  # è¿”å›æœ€åä¸€ä¸ªæ‰¾åˆ°çš„ JSON

        # (å·²ä¿®æ”¹)

    async def create_persona(self,
                             persona_prompt_template: str,
                             used_aliases: List[str],
                             stream_chunk_cb: Callable[[str], Awaitable[None]]) -> Tuple[str, str | None]:
        """
        (å·²ä¿®æ”¹)
        æ¥æ”¶å·²ä½¿ç”¨çš„ä»£å·åˆ—è¡¨ï¼Œç›´æ¥è¿”å›å®Œæ•´çš„ intro_textï¼Œå¹¶ä½¿ç”¨ self.name ä½œä¸ºé»˜è®¤ aliasã€‚
        """
        template = persona_prompt_template
        if not template:
            return f"(é”™è¯¯: æ— æ³•è¯»å–äººè®¾ Prompt)", None

        used_aliases_str = "\n".join(used_aliases) if used_aliases else "æ— "

        # ğŸ“Œ [ä¿®å¤] ä¼ é€’å·²ä½¿ç”¨çš„å®Œæ•´äººè®¾æ–‡æœ¬ï¼Œè®© AI è‡ªå·±å»ç†è§£å’Œè§£æé¿å…é‡å¤
        prompt = template.format(self_name=self.name, used_aliases_str=used_aliases_str)
        messages = [{"role": "user", "content": prompt}]

        try:
            full_intro = await self.llm_client.chat_stream(
                messages,
                model=self.model_name,
                stream_callback=stream_chunk_cb
            )

            intro_text = full_intro.strip().replace("\n", " ")
            if not intro_text:
                return f"å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ {self.name}ï¼Œå¾ˆé«˜å…´è®¤è¯†å„ä½ã€‚", None

            # ğŸ“Œ [ç®€åŒ–é€»è¾‘] ç›´æ¥ä½¿ç”¨ç©å®¶åä½œä¸º Aliasã€‚è®© AI è‡ªå·±å»ç†è§£é¿å…é‡å¤ã€‚
            # AI çš„ä»»åŠ¡ç°åœ¨æ˜¯ï¼šç¡®ä¿å®ƒè¾“å‡ºçš„ "ä»£å·/å§“å" åœ¨ used_aliases_str ä¸­æ²¡æœ‰å‡ºç°ã€‚
            alias = self.name

            return intro_text, alias

        except Exception as e:
            error_msg = f"(åˆ›å»ºäººè®¾æ—¶å‡ºé”™: {str(e)})"
            return error_msg, None

    # (å·²ä¿®æ”¹)
    async def decide_action(self,
                            game_state_summary: str,
                            my_hand: str,
                            available_actions_str: str,
                            next_player_name: str,
                            my_persona: str,
                            opponent_personas: str,
                            opponent_reflections: str,
                            opponent_private_impressions_str: str,
                            observed_speech_str: str,
                            received_secret_messages: str,
                            player_inventory: str,
                            field_item_intel: str,  # (æ–°) æ·»åŠ 
                            min_raise_increment: int,
                            dealer_name: str,
                            observed_moods: str,
                            multiplier: int,
                            call_cost: int,
                            table_seating_str: str,
                            opponent_reference_str: str,
                            public_event_log: str, # (æ–°) æ·»åŠ 
                    prompt_template: str, # (æ–°) æ·»åŠ 
                    stream_start_cb: Callable[[str], Awaitable[None]],
                    stream_chunk_cb: Callable[[str], Awaitable[None]]) -> dict:
        """
        (å·²ä¿®æ”¹)
        æå¤§å¢å¼º except å—çš„æ—¥å¿—è®°å½•èƒ½åŠ›ã€‚
        """
        full_content_debug = ""  # (æ–°) ç”¨äºåœ¨å‡ºé”™æ—¶è®°å½•
        try:
            # template = self._read_file(DECIDE_ACTION_PROMPT_PATH) # <-- [ä¿®å¤] ç§»é™¤
            template = prompt_template  # <-- [ä¿®å¤] ä½¿ç”¨ä¼ å…¥çš„æ¨¡æ¿
            if not template:
                raise RuntimeError("æ— æ³•è¯»å– Prompt æ¨¡æ¿æ–‡ä»¶ã€‚")

            prompt = template.format(
                self_name=self.name,
                game_state_summary=game_state_summary,
                my_hand=my_hand,
                available_actions=available_actions_str,
                next_player_name=next_player_name,
                my_persona=my_persona,
                opponent_personas=opponent_personas,
                opponent_reflections=opponent_reflections,
                opponent_private_impressions_str=opponent_private_impressions_str,
                observed_speech_str=observed_speech_str,
                received_secret_messages=received_secret_messages,
                player_inventory=player_inventory,
                field_item_intel=field_item_intel,  # (æ–°) æ·»åŠ 
                min_raise_increment=min_raise_increment,
                dealer_name=dealer_name,
                observed_moods=observed_moods,
                multiplier=multiplier,
                call_cost=call_cost,
                table_seating=table_seating_str,
                public_event_log=public_event_log, # (æ–°) æ·»åŠ 
                opponent_reference=opponent_reference_str
            )
            messages = [{"role": "user", "content": prompt}]

            await stream_start_cb(f"[{self.name} æ€è€ƒä¸­...]: ")

            full_content = await self.llm_client.chat_stream(
                messages,
                model=self.model_name,
                stream_callback=stream_chunk_cb
            )
            full_content_debug = full_content  # (æ–°) å­˜å‚¨

            result = self._parse_first_valid_json(full_content)

            if result and "action" in result and "reason" in result and "mood" in result:
                return result

            # (æ–°) å°è¯•æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°æ¨æ–­åŠ¨ä½œï¼Œé¿å…ç›´æ¥åˆ¤å®šå¤±è´¥
            inferred_action = self._infer_action_from_text(full_content)
            if inferred_action:
                await stream_chunk_cb("\n[ç³»ç»Ÿæç¤º: æœªæ£€æµ‹åˆ° JSONï¼Œå·²æ ¹æ®æè¿°æ¨æ–­åŠ¨ä½œã€‚]")
                return inferred_action

            raise ValueError(f"LLM æœªè¿”å›æœ‰æ•ˆçš„ JSONã€‚")

        except Exception as e:
            # --- (æ–°) å¢å¼ºçš„é”™è¯¯æŠ¥å‘Š ---
            tb_str = traceback.format_exc()  # è·å–å®Œæ•´çš„å †æ ˆè·Ÿè¸ª

            # å‡†å¤‡ä¸€ä¸ªéå¸¸è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_msg = f"""LLM è§£æå¤±è´¥:

            Exception Type: {type(e)}
            Exception: {str(e)}

            Full Content Received:
            ---
            {full_content_debug[:200]}...
            ---

            Traceback:
            {tb_str}
            """

            # (æ–°) æ›¿æ¢æ¢è¡Œç¬¦ï¼Œä»¥ä¾¿åœ¨ JSON å’Œæ—¥å¿—ä¸­å®‰å…¨ä¼ è¾“
            error_msg_oneline = error_msg.replace("\n", " || ")

            print(f"ã€ä¸Šå¸(è­¦å‘Š)ã€‘: {self.name} è§£ææµå¼JSONå¤±è´¥: {error_msg_oneline}")
            await stream_chunk_cb(f"\n[LLM è§£æå¤±è´¥: {error_msg_oneline}]")

            return {"action": "FOLD", "reason": error_msg_oneline, "target_name": None, "mood": "è§£æå¤±è´¥",
                    "speech": None,
                    "secret_message": None}
            # --- ä¿®å¤ç»“æŸ ---

    def _infer_action_from_text(self, text: str) -> Optional[Dict]:
        """(æ–°) å½“ LLM æœªè¾“å‡ºåˆæ³• JSON æ—¶ï¼Œæ ¹æ®æ–‡æœ¬å†…å®¹æ¨æµ‹ç©å®¶æ„å›¾ã€‚"""
        if not text:
            return None

        normalized = text.strip()
        if not normalized:
            return None

        # å®šä¹‰å…³é”®å­—æ˜ å°„
        action_keywords = {
            "ALL_IN_SHOWDOWN": ["ALL_IN_SHOWDOWN", "ALL IN", "ALL-IN", "ALLIN", "å…¨ä¸‹", "å­¤æ³¨ä¸€æ·", "æ¢­å“ˆ"],
            "CALL": ["CALL", "è·Ÿæ³¨", "è·Ÿä¸Š", "è·Ÿåˆ°åº•"],
            "FOLD": ["FOLD", "å¼ƒç‰Œ", "æ”¾å¼ƒ", "æ‰”ç‰Œ"],
            "LOOK": ["LOOK", "çœ‹ç‰Œ", "å…ˆçœ‹ç‰Œ"],
        }

        lowered = normalized.lower()

        detected_action: Optional[str] = None
        detected_phrase: Optional[str] = None
        detected_reason: Optional[str] = None
        detected_mood: Optional[str] = None
        detected_speech: Optional[str] = None

        # (æ–°) ä¼˜å…ˆå°è¯•è§£æå½¢å¦‚ â€œåŠ¨ä½œ: XXXâ€ çš„ç»“æ„åŒ–æè¿°
        structured_patterns = {
            "action": [r"(?:åŠ¨ä½œ|å†³å®š|é€‰æ‹©|è¡ŒåŠ¨|move|action)[:ï¼š]\s*([^\nã€‚ï¼ï¼Ÿ]+)"],
            "reason": [r"(?:ç†ç”±|åŸå› |è§£æ|è¯´æ˜)[:ï¼š]\s*([^\nã€‚ï¼ï¼Ÿ]+)"],
            "mood": [r"(?:æƒ…ç»ª|å¿ƒæƒ…|çŠ¶æ€|Mood)[:ï¼š]\s*([^\nã€‚ï¼ï¼Ÿ]+)"],
            "speech": [r"(?:å‘è¨€|è¯è¯­|å°è¯|å®£è¨€|è¯´)[:ï¼š]\s*([^\nã€‚ï¼ï¼Ÿ]+)"],
        }

        structured_info: Dict[str, str] = {}
        for field, patterns in structured_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, normalized, re.IGNORECASE)
                if match:
                    structured_info[field] = match.group(1).strip()
                    break

        if "action" in structured_info:
            action_value = structured_info["action"].lower()
            for action, keywords in action_keywords.items():
                for keyword in keywords:
                    if keyword.lower() in action_value:
                        detected_action = action
                        detected_phrase = structured_info["action"]
                        break
                if detected_action:
                    break

        detected_reason = structured_info.get("reason")
        detected_mood = structured_info.get("mood")
        detected_speech = structured_info.get("speech")

        sentences = re.split(r"[ã€‚ï¼ï¼Ÿ\n]", normalized)
        if not detected_action:
            for sentence in sentences:
                sentence_stripped = sentence.strip()
                if not sentence_stripped:
                    continue
                sentence_lower = sentence_stripped.lower()
                for action, keywords in action_keywords.items():
                    for keyword in keywords:
                        kw_lower = keyword.lower()
                        if kw_lower in sentence_lower:
                            detected_action = action
                            detected_phrase = sentence_stripped
                            break
                    if detected_action:
                        break
                if detected_action:
                    break

        if not detected_action:
            # å°è¯•ç›´æ¥ä»å…¨æ–‡ä¸­æœç´¢
            for action, keywords in action_keywords.items():
                for keyword in keywords:
                    if keyword.lower() in lowered:
                        detected_action = action
                        detected_phrase = keyword
                        break
                if detected_action:
                    break

        if not detected_action:
            return None

        # ä»…å½“åŠ¨ä½œä¸éœ€è¦é¢å¤–ä¿¡æ¯æ—¶æ‰è¿”å›ï¼Œé¿å…äº§ç”Ÿéæ³•å†³ç­–
        if detected_action in {"RAISE", "COMPARE", "ACCUSE"}:
            return None

        if not detected_reason:
            # (æ–°) å¦‚æœæœªé€šè¿‡ç»“æ„åŒ–ä¿¡æ¯è·å¾—ç†ç”±ï¼Œåˆ™å°è¯•ä½¿ç”¨åŒ…å«åŠ¨ä½œçš„è¯­å¥
            detected_reason = detected_phrase

        mood_keywords = [
            "è‡ªä¿¡", "ç´§å¼ ", "æ²®ä¸§", "æ„¤æ€’", "å…´å¥‹", "å¹³é™", "æ·¡å®š", "ææƒ§", "ç»æœ›", "æœŸå¾…", "å†·é™", "å¿å¿‘", "æ¿€åŠ¨", "ç„¦è™‘"
        ]
        if not detected_mood:
            for mood_word in mood_keywords:
                if mood_word in normalized:
                    detected_mood = mood_word
                    break

        if not detected_mood:
            detected_mood = self.get_pressure_descriptor()

        if detected_reason:
            detected_reason = detected_reason.strip()
        else:
            detected_reason = detected_phrase or detected_action

        action_display = {
            "ALL_IN_SHOWDOWN": "å…¨ä¸‹",
            "CALL": "è·Ÿæ³¨",
            "FOLD": "å¼ƒç‰Œ",
            "LOOK": "çœ‹ç‰Œ",
            "CHECK": "è¿‡ç‰Œ",
        }
        action_cn = action_display.get(detected_action, detected_action)
        phrase_for_reason = detected_reason or detected_phrase or detected_action
        reason = f"LLM æœªè¾“å‡º JSONï¼Œä¾æ®æè¿°â€œ{phrase_for_reason}â€æ¨æµ‹æ‰§è¡Œ {action_cn}ã€‚"

        inferred_result = {
            "action": detected_action,
            "amount": None,
            "target_name": None,
            "target_name_2": None,
            "reason": reason,
            "mood": detected_mood,
            "speech": detected_speech,
            "secret_message": None,
            "cheat_move": None,
        }

        return inferred_result

    # (å·²ä¿®æ”¹)
    async def defend(self,
                     defend_prompt_template: str,  # <-- [ä¿®å¤] æ·»åŠ æ¨¡æ¿å‚æ•°
                     accuser_name: str,
                     partner_name: str,
                     evidence_log: str,
                     my_persona: str,  # (æ–°) æ·»åŠ äººè®¾å‚æ•°
                     stream_start_cb: Callable[[str], Awaitable[None]],
                     stream_chunk_cb: Callable[[str], Awaitable[None]]) -> str:

        # template = self._read_file(DEFEND_PROMPT_PATH) # <-- [ä¿®å¤] ç§»é™¤
        template = defend_prompt_template  # <-- [ä¿®å¤] ä½¿ç”¨ä¼ å…¥çš„æ¨¡æ¿
        if not template:
            return "æˆ‘æ— è¯å¯è¯´ã€‚"

        prompt = template.format(
            self_name=self.name,
            accuser_name=accuser_name,
            partner_name=partner_name,
            evidence_log=evidence_log,
            my_persona=my_persona  # (æ–°) æ·»åŠ äººè®¾
        )
        messages = [{"role": "user", "content": prompt}]

        await stream_start_cb(f"ã€ä¸Šå¸(è¢«å‘Šè¾©æŠ¤)ã€‘: [{self.name}]: ")
        try:
            full_defense = await self.llm_client.chat_stream(
                messages,
                model=self.model_name,
                stream_callback=stream_chunk_cb
            )
            await stream_chunk_cb("\n")
            return full_defense.strip().replace("\n", " ")
        except Exception as e:
            await stream_chunk_cb(f"\nè¾©æŠ¤æ—¶å‡ºé”™: {str(e)}\n")
            return f"è¾©æŠ¤æ—¶å‡ºé”™: {str(e)}"

    # (å·²ä¿®æ”¹)
    async def vote(self,
                   vote_prompt_template: str,  # <-- [ä¿®å¤] æ·»åŠ æ¨¡æ¿å‚æ•°
                   accuser_name: str,
                   target_name_1: str,
                   target_name_2: str,
                   evidence_log: str,
                   defense_speech_1: str,
                   defense_speech_2: str,
                   my_persona: str,  # (æ–°) æ·»åŠ äººè®¾å‚æ•°
                   previous_jury_reason: str = "",  # (æ–°å¢) å‰ä¸€ä½é™ªå®¡å›¢æˆå‘˜çš„ç†ç”±
                   stream_start_cb: Callable[[str], Awaitable[None]] = None,
                   stream_chunk_cb: Callable[[str], Awaitable[None]] = None) -> dict:

        # template = self._read_file(VOTE_PROMPT_PATH) # <-- [ä¿®å¤] ç§»é™¤
        template = vote_prompt_template  # <-- [ä¿®å¤] ä½¿ç”¨ä¼ å…¥çš„æ¨¡æ¿
        if not template:
            return {"vote": "NOT_GUILTY", "reason": "æ¨¡æ¿é”™è¯¯", "thinking_process": ""}

        # å¤„ç†å‰ä¸€ä½é™ªå®¡å›¢ç†ç”±çš„æ˜¾ç¤º
        if not previous_jury_reason:
            previous_jury_reason = "æ— å‰ä¸€ä½é™ªå®¡å›¢æˆå‘˜çš„æ„è§"

        prompt = template.format(
            self_name=self.name,
            accuser_name=accuser_name,
            target_name_1=target_name_1,
            target_name_2=target_name_2,
            evidence_log=evidence_log,
            defense_speech_1=defense_speech_1,
            defense_speech_2=defense_speech_2,
            my_persona=my_persona,  # (æ–°) æ·»åŠ äººè®¾
            previous_jury_reason=previous_jury_reason  # (æ–°å¢) å‰ä¸€ä½é™ªå®¡å›¢ç†ç”±
        )
        messages = [{"role": "user", "content": prompt}]

        if stream_start_cb:
            await stream_start_cb(f"ã€ä¸Šå¸(é™ªå®¡å›¢æŠ•ç¥¨)ã€‘: [{self.name} æ­£åœ¨ç§˜å¯†æŠ•ç¥¨...]: ")

        try:
            thinking_buffer = ""
            def collect_thinking(chunk: str):
                nonlocal thinking_buffer
                thinking_buffer += chunk
                if stream_chunk_cb:
                    asyncio.create_task(stream_chunk_cb(chunk))

            full_content = await self.llm_client.chat_stream(
                messages,
                model=self.model_name,
                stream_callback=collect_thinking
            )

            json_match = re.search(r'```json\s*({[\s\S]*?})\s*```|\s*({[\s\S]*})', full_content)
            if json_match:
                json_str = json_match.group(1) or json_match.group(2)
                result = json.loads(json_str)
                vote = result.get("vote", "NOT_GUILTY").upper()
                thinking_process = result.get("thinking_process", "")
                reason = result.get("reason", "åˆ†æè¿‡ç¨‹å‡ºé”™")

                # ç¡®ä¿è¿”å›å®Œæ•´çš„æŠ•ç¥¨ä¿¡æ¯
                return {
                    "vote": vote,
                    "reason": reason,
                    "thinking_process": thinking_process,
                    "full_response": full_content
                }

            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            return {
                "vote": "NOT_GUILTY",
                "reason": "æŠ•ç¥¨è§£æå¤±è´¥",
                "thinking_process": "æ— æ³•è§£æAIå›å¤",
                "full_response": full_content
            }

        except Exception as e:
            error_msg = f"æŠ•ç¥¨æ—¶å‡ºé”™: {str(e)}"
            if stream_chunk_cb:
                await stream_chunk_cb(f"\n{error_msg} (è‡ªåŠ¨æŠ•: æ— ç½ª)\n")
            return {
                "vote": "NOT_GUILTY",
                "reason": error_msg,
                "thinking_process": "ç³»ç»Ÿé”™è¯¯",
                "full_response": ""
            }

    async def decide_bribe(self,
                           bribe_prompt_template: str,
                           bribe_cost: int,
                           success_chance: float,
                           penalty_chips: int,
                           # â†“â†“ åœ¨è¿™é‡Œæ·»åŠ ä¸¤ä¸ªæ–°å‚æ•° â†“â†“
                           payment_method_string: str,
                           consequence_string: str,
                           # â†‘â†‘ æ·»åŠ å®Œæ¯• â†‘â†‘
                           stream_start_cb: Callable[[str], Awaitable[None]],
                           stream_chunk_cb: Callable[[str], Awaitable[None]]) -> dict:
        """(æ–°) ç©å®¶å†³å®šæ˜¯å¦è´¿èµ‚"""
        if not bribe_prompt_template:
            return {"bribe": False, "reason": "ç³»ç»Ÿé”™è¯¯ï¼šè´¿èµ‚æ¨¡æ¿æœªåŠ è½½"}

        prompt = bribe_prompt_template.format(
            self_name=self.name,
            bribe_cost=bribe_cost,
            success_chance_percent=success_chance * 100.0,
            penalty_chips=penalty_chips,
            success_chance=success_chance,  # (ä¸ºé˜²ä¸‡ä¸€ï¼Œä¹Ÿä¼ å…¥åŸå§‹å°æ•°)
            # â†“â†“ åœ¨è¿™é‡Œæ·»åŠ ä¸¤ä¸ªæ–°å‚æ•° â†“â†“
            payment_method_string=payment_method_string,
            consequence_string=consequence_string
            # â†‘â†‘ æ·»åŠ å®Œæ¯• â†‘â†‘
        )
        messages = [{"role": "user", "content": prompt}]

        await stream_start_cb(f"ã€ä¸Šå¸(å¯†è°ˆ)ã€‘: [{self.name} æ­£åœ¨ç´§æ€¥å†³ç­–...]: ")
        try:
            full_content = await self.llm_client.chat_stream(
                messages,
                model=self.model_name,
                stream_callback=stream_chunk_cb
            )
            await stream_chunk_cb("\n")

            result = self._parse_first_valid_json(full_content)
            if result and "bribe" in result:
                return result

            # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œé»˜è®¤æ‹’ç»è´¿èµ‚
            return {"bribe": False, "reason": "JSON è§£æå¤±è´¥æˆ–æœªæä¾› bribe é”®"}

        except Exception as e:
            await stream_chunk_cb(f"\nå†³ç­–è´¿èµ‚æ—¶å‡ºé”™: {str(e)}\n")
            return {"bribe": False, "reason": f"å†³ç­–æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"}

    # (å·²ä¿®æ”¹)
    async def reflect(self,
                      reflect_prompt_template: str,  # <-- [ä¿®å¤] æ·»åŠ æ¨¡æ¿å‚æ•°
                      round_history: str,
                      round_result: str,
                      current_impressions_json: str,
                      # (æ–°) æ·»åŠ  2 ä¸ªå‚æ•°
                      player_self_details: str,
                      opponent_name_list: str,
                      stream_start_cb: Callable[[str], Awaitable[None]],
                      stream_chunk_cb: Callable[[str], Awaitable[None]]) -> (str, dict):
        """
        (å·²ä¿®æ”¹)
        å¢å¼º reflect çš„é”™è¯¯å¤„ç†
        """
        full_content_debug = ""  # (æ–°)
        try:
            # template = self._read_file(REFLECT_PROMPT_PATH) # <-- [ä¿®å¤] ç§»é™¤
            template = reflect_prompt_template  # <-- [ä¿®å¤] ä½¿ç”¨ä¼ å…¥çš„æ¨¡æ¿
            if not template:
                raise RuntimeError("æ— æ³•è¯»å–å¤ç›˜ Prompt")

            prompt = template.format(
                self_name=self.name,
                round_history=round_history,
                round_result=round_result,
                current_impressions_json=current_impressions_json,
                # (æ–°) ä¼ å…¥ 2 ä¸ªå‚æ•°
                player_self_details=player_self_details,
                opponent_name_list=opponent_name_list
            )
            messages = [{"role": "user", "content": prompt}]

            await stream_start_cb(f"ã€ä¸Šå¸(å¤ç›˜ä¸­)ã€‘: [{self.name}]: ")

            await stream_chunk_cb("æ­£åœ¨æ›´æ–°æƒ…æŠ¥...")
            full_content = await self.llm_client.chat_stream(
                messages,
                model=self.model_name,
                stream_callback=lambda s: asyncio.sleep(0.001)
            )
            full_content_debug = full_content  # (æ–°)

            result = self._parse_first_valid_json(full_content)
            if not result:
                raise ValueError(f"LLM æœªè¿”å›æœ‰æ•ˆçš„å¤ç›˜ JSONã€‚")

            public_reflection = result.get("public_reflection", "...")
            private_impressions = result.get("private_impressions", {})

            await stream_chunk_cb(f" (å‘è¨€): {public_reflection}\n")
            return public_reflection, private_impressions

        except Exception as e:
            # (æ–°) å¢å¼ºçš„é”™è¯¯æŠ¥å‘Š
            tb_str = traceback.format_exc()
            tb_str_oneline = tb_str.replace("\n", " || ")
            error_msg = (
                "å¤ç›˜æ—¶å‡ºé”™: "
                f"{type(e)}: {str(e)} || Content: {full_content_debug[:100]}... || Traceback: {tb_str_oneline}"
            )
            await stream_chunk_cb(f"\n{error_msg}\n")
            return f"({error_msg})", {}
